{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ollama from Langchain",
   "id": "3add341c2499c3fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:28.468322Z",
     "start_time": "2024-07-21T00:32:26.985290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Celda 1: Importaciones\n",
    "import os\n",
    "from typing import List, Any\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from pydantic import Field\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from rouge import Rouge\n",
    "import time\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "8ff458e1964993a8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:36.721759Z",
     "start_time": "2024-07-21T00:32:29.110366Z"
    }
   },
   "source": [
    "llm = Ollama(model=\"llama3\")\n",
    "llm.invoke(\"Hola, ¿Quién eres?\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola! Soy un modelo de lenguaje entrenado por una empresa llamada Meta AI. Mi función es poder responder preguntas y mantener conversaciones en diferentes idiomas, incluyendo el español. Me llamo LLaMA (Large Language Model Application), y estoy aquí para ayudarte con cualquier tema que tengas en mente. ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RAG",
   "id": "72f4dfe98bdf89c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Document",
   "id": "ee78810e354ee92a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:40.942295Z",
     "start_time": "2024-07-21T00:32:40.935930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Celda 1: Clase DocumentLoader\n",
    "\n",
    "class DocumentLoader:\n",
    "    \"\"\"\n",
    "    Clase estática para cargar documentos PDF y archivos CSV.\n",
    "\n",
    "    Esta clase proporciona métodos estáticos para cargar múltiples documentos PDF\n",
    "    de un directorio y para cargar un archivo CSV como un DataFrame de pandas.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def load_pdfs(directory: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Carga todos los archivos PDF de un directorio especificado.\n",
    "\n",
    "        Este método recorre el directorio dado, carga cada archivo PDF encontrado\n",
    "        utilizando PyMuPDFLoader, y devuelve una lista de objetos Document.\n",
    "\n",
    "        Args:\n",
    "            directory (str): Ruta al directorio que contiene los archivos PDF.\n",
    "\n",
    "        Returns:\n",
    "            List[Document]: Una lista de objetos Document, cada uno representando\n",
    "                            el contenido de un archivo PDF.\n",
    "\n",
    "        Nota:\n",
    "            Los archivos que no terminan en '.pdf' son ignorados.\n",
    "        \"\"\"\n",
    "        pdf_docs = []\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.pdf'):\n",
    "                loader = PyMuPDFLoader(os.path.join(directory, filename))\n",
    "                pdf_docs.extend(loader.load())\n",
    "        return pdf_docs\n",
    "\n",
    "    @staticmethod\n",
    "    def load_csv(file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Carga un archivo CSV y lo devuelve como un DataFrame de pandas.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Ruta al archivo CSV a cargar.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Un DataFrame de pandas que contiene los datos del CSV.\n",
    "\n",
    "        Nota:\n",
    "            Este método utiliza la función read_csv de pandas con sus configuraciones\n",
    "            por defecto. Para casos de uso específicos, puede ser necesario ajustar\n",
    "            los parámetros de lectura del CSV.\n",
    "        \"\"\"\n",
    "        return pd.read_csv(file_path)"
   ],
   "id": "8667ddf1798665cf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:41.763754Z",
     "start_time": "2024-07-21T00:32:41.562092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uso de la clase DocumentLoader\n",
    "\n",
    "pdf_docs = DocumentLoader.load_pdfs(\"../data/GuideLines\")\n",
    "df = DocumentLoader.load_csv('../data/raw_data/BankCustomerChurnPrediction.csv')\n",
    "\n",
    "print(f\"Number of PDF documents loaded: {len(pdf_docs)}\")\n",
    "print(f\"CSV data loaded with shape: {df.shape}\")"
   ],
   "id": "bf3f3a1090407335",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PDF documents loaded: 2\n",
      "CSV data loaded with shape: (10000, 12)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:42.746117Z",
     "start_time": "2024-07-21T00:32:42.740712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.document_loader import DocumentLoader\n",
    "from src.utils.document_processor import DataProcessor\n",
    "\n",
    "\n",
    "class DocumentManager:\n",
    "    \"\"\"\n",
    "    Gestiona la carga y procesamiento de documentos PDF y archivos CSV.\n",
    "\n",
    "    Esta clase coordina el uso de DocumentLoader para cargar documentos y\n",
    "    DataProcessor para procesar los documentos cargados.\n",
    "\n",
    "    Atributos:\n",
    "        pdf_directory (str): Ruta al directorio que contiene los archivos PDF.\n",
    "        csv_file (str): Ruta al archivo CSV a procesar.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pdf_directory: str, csv_file: str):\n",
    "        \"\"\"\n",
    "        Inicializa el DocumentManager con las rutas de los documentos.\n",
    "\n",
    "        Args:\n",
    "            pdf_directory (str): Ruta al directorio que contiene los archivos PDF.\n",
    "            csv_file (str): Ruta al archivo CSV a procesar.\n",
    "        \"\"\"\n",
    "        self.pdf_directory = pdf_directory\n",
    "        self.csv_file = csv_file\n",
    "\n",
    "    def load_and_process_documents(self):\n",
    "        \"\"\"\n",
    "        Carga y procesa los documentos PDF y el archivo CSV.\n",
    "\n",
    "        Este método realiza las siguientes operaciones:\n",
    "        1. Carga los documentos PDF del directorio especificado.\n",
    "        2. Carga el archivo CSV.\n",
    "        3. Divide los documentos PDF.\n",
    "        4. Crea un resumen del CSV.\n",
    "        5. Crea documentos individuales a partir del CSV.\n",
    "        6. Combina todos los documentos procesados en una sola lista.\n",
    "\n",
    "        Returns:\n",
    "            list: Una lista que contiene el resumen del CSV, los documentos\n",
    "                  individuales del CSV y los documentos PDF divididos.\n",
    "        \"\"\"\n",
    "        # Cargar documentos\n",
    "        pdf_docs = DocumentLoader.load_pdfs(self.pdf_directory)\n",
    "        df = DocumentLoader.load_csv(self.csv_file)\n",
    "\n",
    "        # Procesar documentos\n",
    "        split_docs = DataProcessor.split_documents(pdf_docs)\n",
    "        csv_summary_doc = DataProcessor.create_csv_summary(df)\n",
    "        csv_docs = DataProcessor.create_csv_docs(df)\n",
    "\n",
    "        # Combinar y retornar todos los documentos procesados\n",
    "        return [csv_summary_doc] + csv_docs + split_docs"
   ],
   "id": "bb5565fb42385109",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:43.438768Z",
     "start_time": "2024-07-21T00:32:43.391035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejemplo de uso:\n",
    "doc_manager = DocumentManager(\"../data/GuideLines\", \"../data/raw_data/BankCustomerChurnPrediction.csv\")\n",
    "processed_docs = doc_manager.load_and_process_documents()\n",
    "\n",
    "print(f\"Total number of documents: {len(processed_docs)}\")"
   ],
   "id": "4dd432a6c3fb49f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1004\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:44.050581Z",
     "start_time": "2024-07-21T00:32:44.046685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    Clase estática para procesar documentos y datos CSV.\n",
    "\n",
    "    Proporciona métodos para dividir documentos, crear resúmenes de CSV\n",
    "    y generar documentos a partir de registros CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def split_documents(docs: List[Document], chunk_size: int = 2000, chunk_overlap: int = 500) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Divide una lista de documentos en chunks más pequeños.\n",
    "\n",
    "        Args:\n",
    "            docs (List[Document]): Lista de documentos a dividir.\n",
    "            chunk_size (int, optional): Tamaño de cada chunk. Por defecto 2000.\n",
    "            chunk_overlap (int, optional): Superposición entre chunks. Por defecto 500.\n",
    "\n",
    "        Returns:\n",
    "            List[Document]: Lista de documentos divididos.\n",
    "        \"\"\"\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        return text_splitter.split_documents(docs)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_csv_summary(df: pd.DataFrame) -> Document:\n",
    "        \"\"\"\n",
    "        Crea un resumen del DataFrame CSV.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame de pandas con los datos CSV.\n",
    "\n",
    "        Returns:\n",
    "            Document: Un objeto Document que contiene el resumen del CSV.\n",
    "\n",
    "        Nota:\n",
    "            El resumen incluye estadísticas clave como el número total de filas,\n",
    "            clientes únicos, rango de edades, países representados, etc.\n",
    "        \"\"\"\n",
    "        csv_summary = f\"\"\"\n",
    "        RESUMEN IMPORTANTE DEL CSV 'BankCustomerChurnPrediction.csv':\n",
    "        - Total de filas y clientes únicos: {len(df)}\n",
    "        - Número exacto de clientes únicos: {df['customer_id'].nunique()}\n",
    "        - Columnas: {', '.join(df.columns)}\n",
    "        - Rango de edades: {df['age'].min()} - {df['age'].max()} años\n",
    "        - Países representados: {', '.join(df['country'].unique())}\n",
    "        - Saldo promedio: {df['balance'].mean():.2f}\n",
    "        - Porcentaje de clientes con tarjeta de crédito: {(df['credit_card'].sum() / len(df) * 100):.2f}%\n",
    "        - Tasa de abandono (churn): {(df['churn'].sum() / len(df) * 100):.2f}%\n",
    "\n",
    "        Esta información es un resumen preciso basado en el análisis del archivo CSV completo.\n",
    "        Para preguntas sobre estadísticas generales o totales, utiliza siempre esta información.\n",
    "        \"\"\"\n",
    "        return Document(page_content=csv_summary, metadata={\"source\": \"CSV_summary\", \"importance\": 10})\n",
    "\n",
    "    @staticmethod\n",
    "    def create_csv_docs(df: pd.DataFrame, sample_size: int = 1000) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Crea una lista de documentos a partir de una muestra del DataFrame CSV.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame de pandas con los datos CSV.\n",
    "            sample_size (int, optional): Tamaño de la muestra a tomar. Por defecto 1000.\n",
    "\n",
    "        Returns:\n",
    "            List[Document]: Lista de objetos Document, cada uno representando una fila del CSV.\n",
    "\n",
    "        Nota:\n",
    "            Utiliza un muestreo aleatorio con una semilla fija para reproducibilidad.\n",
    "        \"\"\"\n",
    "        csv_sample = df.sample(n=sample_size, random_state=42)\n",
    "        return [Document(page_content=row.to_json(), metadata={\"source\": \"CSV_record\", \"importance\": 1})\n",
    "                for _, row in csv_sample.iterrows()]"
   ],
   "id": "9f5ca1b6d8bf45f0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:44.800071Z",
     "start_time": "2024-07-21T00:32:44.742508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uso de la clase DocumentManager\n",
    "docs = DocumentLoader.load_pdfs(\"../data/GuideLines\")\n",
    "split_docs = DataProcessor.split_documents(docs)\n",
    "print(f\"Total number of split documents: {len(split_docs)}\")\n",
    "\n",
    "df = pd.read_csv('../data/raw_data/BankCustomerChurnPrediction.csv')\n",
    "csv_summary = DataProcessor.create_csv_summary(df)\n",
    "csv_docs = DataProcessor.create_csv_docs(df)\n",
    "\n",
    "print(f\"CSV summary document created with importance: {csv_summary.metadata.get('importance')}\")\n",
    "print(f\"Total number of CSV records: {len(csv_docs)}\")\n",
    "\n",
    "print(f\"Content of CSV summary document: {csv_summary.page_content[:200]}...\")  # Mostramos solo los primeros 200 caracteres\n",
    "print(f\"Content of first CSV record document: {csv_docs[0].page_content[:200]}...\")  # Mostramos solo los primeros 200 caracteres"
   ],
   "id": "a3e76bd70f584591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of split documents: 3\n",
      "CSV summary document created with importance: 10\n",
      "Total number of CSV records: 1000\n",
      "Content of CSV summary document: \n",
      "        RESUMEN IMPORTANTE DEL CSV 'BankCustomerChurnPrediction.csv':\n",
      "        - Total de filas y clientes únicos: 10000\n",
      "        - Número exacto de clientes únicos: 10000\n",
      "        - Columnas: customer_...\n",
      "Content of first CSV record document: {\"customer_id\":15687492,\"credit_score\":596,\"country\":\"Germany\",\"gender\":\"Male\",\"age\":32,\"tenure\":3,\"balance\":96709.07,\"products_number\":2,\"credit_card\":0,\"active_member\":0,\"estimated_salary\":41788.37,...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:32:45.637535Z",
     "start_time": "2024-07-21T00:32:45.634856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Celda 6: Clase VectorStoreManager\n",
    "class VectorStoreManager:\n",
    "    \"\"\"\n",
    "    Gestor para la creación y manejo de un almacén de vectores Chroma.\n",
    "\n",
    "    Esta clase facilita la creación de un almacén de vectores persistente\n",
    "    utilizando documentos y un modelo de embeddings proporcionados.\n",
    "\n",
    "    Atributos:\n",
    "        embed_model: El modelo de embeddings a utilizar para vectorizar los documentos.\n",
    "        base_dir (str): El directorio base donde se almacenará el almacén de vectores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_model, base_dir):\n",
    "        \"\"\"\n",
    "        Inicializa el VectorStoreManager.\n",
    "\n",
    "        Args:\n",
    "            embed_model: El modelo de embeddings a utilizar.\n",
    "            base_dir (str): El directorio base para almacenar los datos del almacén de vectores.\n",
    "        \"\"\"\n",
    "        self.embed_model = embed_model\n",
    "        self.base_dir = base_dir\n",
    "\n",
    "    def create_vector_store(self, documents):\n",
    "        \"\"\"\n",
    "        Crea y persiste un almacén de vectores Chroma a partir de los documentos proporcionados.\n",
    "\n",
    "        Este método vectoriza los documentos utilizando el modelo de embeddings especificado\n",
    "        y los almacena en un directorio persistente.\n",
    "\n",
    "        Args:\n",
    "            documents (List[Document]): Lista de documentos a vectorizar y almacenar.\n",
    "\n",
    "        Returns:\n",
    "            Chroma: Una instancia del almacén de vectores Chroma creado.\n",
    "\n",
    "        Nota:\n",
    "            El almacén de vectores se guarda en un subdirectorio 'bank_data_db' dentro del directorio base.\n",
    "            La colección se nombra 'bank_regulations_and_data'.\n",
    "        \"\"\"\n",
    "        persist_directory = os.path.join(self.base_dir, \"bank_data_db\")\n",
    "        return Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=self.embed_model,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=\"bank_regulations_and_data\"\n",
    "        )"
   ],
   "id": "9376e80641f0fddb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:33:39.631061Z",
     "start_time": "2024-07-21T00:32:46.355513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejemplo de uso:\n",
    "embed_model = FastEmbedEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "base_dir = \"../data\"\n",
    "vector_store_manager = VectorStoreManager(embed_model, base_dir)\n",
    "documents = split_docs + [csv_summary] + csv_docs\n",
    "vector_store = vector_store_manager.create_vector_store(documents)\n",
    "\n",
    "print(f\"Vector store created with {vector_store._collection.count()} documents\")"
   ],
   "id": "5bcd2cb25248d69e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33e96e09414e4d55b2fe3b1ed8ccec28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 62338 documents\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:33:44.923654Z",
     "start_time": "2024-07-21T00:33:44.914072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    Un recuperador personalizado que realiza búsquedas en un almacén de vectores,\n",
    "    priorizando los documentos de resumen CSV y complementando con otros documentos relevantes.\n",
    "\n",
    "    Atributos:\n",
    "        vectorstore (Any): El almacén de vectores utilizado para las búsquedas de similitud.\n",
    "\n",
    "    Configuración:\n",
    "        arbitrary_types_allowed (bool): Permite tipos arbitrarios en la configuración de Pydantic.\n",
    "    \"\"\"\n",
    "\n",
    "    vectorstore: Any = Field(default=None, description=\"Almacén de vectores para búsquedas de similitud\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Recupera documentos relevantes basados en la consulta proporcionada.\n",
    "\n",
    "        Este método realiza dos búsquedas:\n",
    "        1. Busca un documento de resumen CSV.\n",
    "        2. Busca otros documentos relevantes.\n",
    "\n",
    "        Luego combina los resultados, asegurándose de que no haya duplicados.\n",
    "\n",
    "        Args:\n",
    "            query (str): La consulta para la cual se buscan documentos relevantes.\n",
    "\n",
    "        Returns:\n",
    "            List[Document]: Una lista de documentos relevantes, con el resumen CSV (si se encuentra) al principio.\n",
    "        \"\"\"\n",
    "        # Busca el documento de resumen CSV\n",
    "        summary_docs = self.vectorstore.similarity_search(query, filter={\"source\": \"CSV_summary\"}, k=1)\n",
    "\n",
    "        # Busca otros documentos relevantes\n",
    "        other_docs = self.vectorstore.similarity_search(query, k=4)\n",
    "\n",
    "        # Combina los resultados, eliminando duplicados\n",
    "        return summary_docs + [doc for doc in other_docs if doc not in summary_docs]\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Versión asíncrona de get_relevant_documents.\n",
    "\n",
    "        Esta implementación simplemente llama a la versión síncrona, pero podría\n",
    "        ser modificada en el futuro para realizar operaciones asíncronas si es necesario.\n",
    "\n",
    "        Args:\n",
    "            query (str): La consulta para la cual se buscan documentos relevantes.\n",
    "\n",
    "        Returns:\n",
    "            List[Document]: Una lista de documentos relevantes.\n",
    "        \"\"\"\n",
    "        return self.get_relevant_documents(query)"
   ],
   "id": "884952b9a0471486",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:33:46.361745Z",
     "start_time": "2024-07-21T00:33:45.686408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejemplo de uso:\n",
    "retriever = CustomRetriever(vectorstore=vector_store)\n",
    "relevant_docs = retriever.get_relevant_documents(\"¿Cuál es el saldo promedio de los clientes?\")\n",
    "\n",
    "print(f\"Total relevant documents found: {len(relevant_docs)}\")\n",
    "print(f\"Document sources: {[doc.metadata.get('source') for doc in relevant_docs]}\")\n",
    "print(f\"First relevant document content: {relevant_docs[0].page_content[:200]}...\")  # Mostramos solo los primeros 200 caracteres"
   ],
   "id": "bd50cf7f12275347",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianinfantes/Library/Caches/pypoetry/virtualenvs/langchainragollama-USdIz_Vs-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total relevant documents found: 5\n",
      "Document sources: ['CSV_summary', '../data/raw_data/BankCustomerChurnPrediction.csv', '../data/raw_data/BankCustomerChurnPrediction.csv', '../data/raw_data/BankCustomerChurnPrediction.csv', '../data/raw_data/BankCustomerChurnPrediction.csv']\n",
      "First relevant document content: \n",
      "IMPORTANTE: Este es un resumen preciso del archivo CSV 'BankCustomerChurnPrediction.csv'.\n",
      "- Total de filas (clientes únicos): 10000\n",
      "- Número exacto de clientes únicos: 10000\n",
      "- Columnas: customer_id, ...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:33:51.070605Z",
     "start_time": "2024-07-21T00:33:51.064410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class QASystem:\n",
    "    \"\"\"\n",
    "    Sistema de preguntas y respuestas que utiliza un modelo de lenguaje y un recuperador personalizado.\n",
    "\n",
    "    Esta clase configura y ejecuta un sistema QA capaz de responder preguntas basadas en\n",
    "    información recuperada de un conjunto de documentos.\n",
    "\n",
    "    Atributos:\n",
    "        llm: El modelo de lenguaje a utilizar para generar respuestas.\n",
    "        custom_retriever: El recuperador personalizado para obtener documentos relevantes.\n",
    "        qa_chain: La cadena de QA configurada (se inicializa en setup_qa_chain).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm, custom_retriever):\n",
    "        \"\"\"\n",
    "        Inicializa el sistema QA.\n",
    "\n",
    "        Args:\n",
    "            llm: El modelo de lenguaje a utilizar.\n",
    "            custom_retriever: El recuperador personalizado para obtener documentos relevantes.\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.custom_retriever = custom_retriever\n",
    "        self.qa_chain = None\n",
    "\n",
    "    def setup_qa_chain(self):\n",
    "        \"\"\"\n",
    "        Configura la cadena de QA con un prompt personalizado.\n",
    "\n",
    "        Esta función crea un PromptTemplate con instrucciones específicas y lo utiliza\n",
    "        para configurar una cadena RetrievalQA.\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"Utiliza la siguiente información para responder a la pregunta del usuario.\n",
    "            IMPORTANTE: Para preguntas sobre datos agregados o estadísticas del banco, SIEMPRE consulta primero el resumen del CSV.\n",
    "            Este resumen contiene información precisa y confiable sobre el conjunto de datos completo.\n",
    "            No te bases en ejemplos individuales para hacer generalizaciones sobre todo el conjunto de datos.\n",
    "\n",
    "            Si la pregunta se refiere a datos numéricos o estadísticas del banco, asegúrate de usar la información del resumen del CSV.\n",
    "            Si no encuentras la respuesta en el resumen, entonces puedes consultar los documentos CSV individuales.\n",
    "            Si aún así no puedes responder, indica que no lo sabes.\n",
    "            No inventes respuestas. Responde en el mismo idioma que la pregunta.\n",
    "\n",
    "            Contexto: {context}\n",
    "            Pregunta: {question}\n",
    "\n",
    "            Proporciona solo la respuesta útil a continuación, nada más. Si la respuesta involucra un recuento o estadística, asegúrate de proporcionar el número exacto encontrado en el resumen del CSV.\n",
    "            Respuesta útil:\n",
    "            \"\"\",\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.custom_retriever,\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs={\"prompt\": prompt}\n",
    "        )\n",
    "\n",
    "    def ask_question(self, question: str):\n",
    "        \"\"\"\n",
    "        Realiza una pregunta al sistema QA.\n",
    "\n",
    "        Esta función utiliza la cadena QA configurada para procesar la pregunta\n",
    "        y generar una respuesta basada en la información recuperada.\n",
    "\n",
    "        Args:\n",
    "            question (str): La pregunta a responder.\n",
    "\n",
    "        Returns:\n",
    "            dict: Un diccionario que contiene la respuesta y los documentos fuente.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Si la cadena QA no ha sido configurada previamente.\n",
    "        \"\"\"\n",
    "        if not self.qa_chain:\n",
    "            raise ValueError(\"QA chain not set up. Run setup_qa_chain first.\")\n",
    "        return self.qa_chain.invoke({\"query\": question})"
   ],
   "id": "dda7a7fadc033657",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:33:59.720881Z",
     "start_time": "2024-07-21T00:33:51.829077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejemplo de uso:\n",
    "llm = Ollama(model=\"llama3\")\n",
    "custom_retriever = CustomRetriever(vectorstore=vector_store)\n",
    "qa_system = QASystem(llm, custom_retriever)\n",
    "qa_system.setup_qa_chain()\n",
    "response = qa_system.ask_question(\"¿Cuál es el saldo promedio de los clientes?\")\n",
    "print(response[\"result\"])"
   ],
   "id": "d03762f41b46e9ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76485.89\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:34:06.440256Z",
     "start_time": "2024-07-21T00:34:06.430541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Celda 9: Clase RAGSystem\n",
    "class RAGSystem:\n",
    "    \"\"\"\n",
    "    Sistema RAG que integra la gestión de documentos, almacenamiento de vectores,\n",
    "    recuperación personalizada y un sistema de preguntas y respuestas.\n",
    "\n",
    "    Esta clase orquesta el flujo completo de un sistema RAG, desde la carga de documentos\n",
    "    hasta la generación de respuestas a preguntas.\n",
    "\n",
    "    Atributos:\n",
    "        document_manager (DocumentManager): Gestor para cargar y procesar documentos.\n",
    "        llm (Ollama): Modelo de lenguaje para generar respuestas.\n",
    "        embed_model (FastEmbedEmbeddings): Modelo de embeddings para vectorizar documentos.\n",
    "        vector_store_manager (VectorStoreManager): Gestor del almacén de vectores.\n",
    "        qa_system (QASystem): Sistema de preguntas y respuestas.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pdf_directory: str, csv_file: str, base_dir: str):\n",
    "        \"\"\"\n",
    "        Inicializa el sistema RAG.\n",
    "\n",
    "        Args:\n",
    "            pdf_directory (str): Ruta al directorio que contiene los archivos PDF.\n",
    "            csv_file (str): Ruta al archivo CSV con datos.\n",
    "            base_dir (str): Directorio base para almacenar el almacén de vectores.\n",
    "        \"\"\"\n",
    "        self.document_manager = DocumentManager(pdf_directory, csv_file)\n",
    "        self.llm = Ollama(model=\"llama3\")\n",
    "        self.embed_model = FastEmbedEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.vector_store_manager = VectorStoreManager(self.embed_model, base_dir)\n",
    "        self.qa_system = None\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Ejecuta el flujo completo del sistema RAG.\n",
    "\n",
    "        Este método carga y procesa los documentos, crea el almacén de vectores,\n",
    "        configura el recuperador personalizado y establece el sistema de preguntas y respuestas.\n",
    "        \"\"\"\n",
    "        # Load and process documents\n",
    "        documents = self.document_manager.load_and_process_documents()\n",
    "        print(f\"Total documents processed: {len(documents)}\")\n",
    "\n",
    "        # Create vector store\n",
    "        vector_store = self.vector_store_manager.create_vector_store(documents)\n",
    "        print(f\"Vector store created with {vector_store._collection.count()} documents\")\n",
    "\n",
    "        # Set up custom retriever\n",
    "        custom_retriever = CustomRetriever(vectorstore=vector_store)\n",
    "\n",
    "        # Set up QA system\n",
    "        self.qa_system = QASystem(self.llm, custom_retriever)\n",
    "        self.qa_system.setup_qa_chain()\n",
    "        print(\"QA system set up successfully\")\n",
    "\n",
    "    def ask_question(self, question: str):\n",
    "        \"\"\"\n",
    "        Realiza una pregunta al sistema RAG.\n",
    "\n",
    "        Args:\n",
    "            question (str): La pregunta a responder.\n",
    "\n",
    "        Returns:\n",
    "            dict: Un diccionario que contiene la respuesta y los documentos fuente.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: Si el sistema QA no ha sido configurado previamente.\n",
    "        \"\"\"\n",
    "        if not self.qa_system:\n",
    "            raise ValueError(\"QA system not set up. Run the 'run' method first.\")\n",
    "        return self.qa_system.ask_question(question)"
   ],
   "id": "51aed85e3aca79e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:35:10.700952Z",
     "start_time": "2024-07-21T00:34:07.136092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Celda 10: Uso del RAGSystem\n",
    "\n",
    "rag_system = RAGSystem(pdf_directory=\"../data/GuideLines\", csv_file=\"../data/raw_data/BankCustomerChurnPrediction.csv\", base_dir=\"../data\")\n",
    "rag_system.run()  # Make sure to set up the system before asking questions\n",
    "response = rag_system.ask_question(\"¿Cuál es el saldo promedio de los clientes?\")\n",
    "print(response[\"result\"])"
   ],
   "id": "53ee500e5372ab2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8e8e1294d81421782f06fbc958b12e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents processed: 1004\n",
      "Vector store created with 63342 documents\n",
      "QA system set up successfully\n",
      "76485.89\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:38:04.905203Z",
     "start_time": "2024-07-21T00:38:04.894674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EvaluationMetrics:\n",
    "    def __init__(self):\n",
    "        self.rouge = Rouge()\n",
    "\n",
    "    def calculate_bleu(self, reference, candidate, max_n=4):\n",
    "        def count_ngrams(sentence, n):\n",
    "            return Counter(zip(*[sentence[i:] for i in range(n)]))\n",
    "\n",
    "        reference_words = reference.split()\n",
    "        candidate_words = candidate.split()\n",
    "\n",
    "        scores = []\n",
    "        for n in range(1, min(max_n, len(candidate_words)) + 1):\n",
    "            ref_ngrams = count_ngrams(reference_words, n)\n",
    "            cand_ngrams = count_ngrams(candidate_words, n)\n",
    "\n",
    "            matches = sum((ref_ngrams & cand_ngrams).values())\n",
    "            total = sum(cand_ngrams.values())\n",
    "\n",
    "            score = matches / total if total > 0 else 0\n",
    "            scores.append(score)\n",
    "\n",
    "        return np.mean(scores) if scores else 0\n",
    "\n",
    "    def calculate_rouge(self, reference, candidate):\n",
    "        try:\n",
    "            scores = self.rouge.get_scores(candidate, reference)\n",
    "            return {\n",
    "                'rouge-1': scores[0]['rouge-1']['f'],\n",
    "                'rouge-2': scores[0]['rouge-2']['f'],\n",
    "                'rouge-l': scores[0]['rouge-l']['f']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error al calcular ROUGE: {e}\")\n",
    "            return {'rouge-1': 0, 'rouge-2': 0, 'rouge-l': 0}\n",
    "\n",
    "    def evaluate_source_relevance(self, question, source_content):\n",
    "        question_words = set(question.lower().split())\n",
    "        source_words = set(source_content.lower().split())\n",
    "        common_words = question_words.intersection(source_words)\n",
    "        return len(common_words) / len(question_words) if question_words else 0\n",
    "\n",
    "    def evaluate_response(self, question, answer, reference_answer, source_content):\n",
    "        bleu_score = self.calculate_bleu(reference_answer, answer)\n",
    "        rouge_scores = self.calculate_rouge(reference_answer, answer)\n",
    "        source_relevance = self.evaluate_source_relevance(question, source_content)\n",
    "\n",
    "        return {\n",
    "            'bleu_score': bleu_score,\n",
    "            'rouge_scores': rouge_scores,\n",
    "            'source_relevance': source_relevance\n",
    "        }\n"
   ],
   "id": "28daa631a6e99163",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:50:46.202749Z",
     "start_time": "2024-07-21T00:50:46.190201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Celda 11: Función para ejecutar pruebas\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "def run_tests(rag_system, questions, reference_answers, output_file='test_results.csv'):\n",
    "    metrics = EvaluationMetrics()\n",
    "    results = []\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['timestamp', 'question', 'answer', 'reference_answer', 'source', 'source_content',\n",
    "                      'bleu_score', 'rouge_scores_rouge-1', 'rouge_scores_rouge-2', 'rouge_scores_rouge-l', 'source_relevance', 'response_time']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for question, reference_answer in zip(questions, reference_answers):\n",
    "            print(f\"\\nPregunta: {question}\")\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                response = rag_system.ask_question(question)\n",
    "                response_time = time.time() - start_time\n",
    "\n",
    "                answer = response[\"result\"]\n",
    "                source = response['source_documents'][0].metadata.get('source', 'No especificada')\n",
    "                source_content = response['source_documents'][0].page_content[:200]\n",
    "\n",
    "                print(f\"Respuesta del modelo: {answer}\")\n",
    "                print(f\"Fuente: {source}\")\n",
    "                print(f\"Contenido de la fuente: {source_content}\")\n",
    "\n",
    "                evaluation_results = metrics.evaluate_response(\n",
    "                    question,\n",
    "                    answer,\n",
    "                    reference_answer,\n",
    "                    source_content\n",
    "                )\n",
    "\n",
    "                evaluation_results.update({\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'question': question,\n",
    "                    'answer': answer,\n",
    "                    'reference_answer': reference_answer,\n",
    "                    'source': source,\n",
    "                    'source_content': source_content,\n",
    "                    'response_time': response_time\n",
    "                })\n",
    "\n",
    "                flattened_results = flatten_dict(evaluation_results)\n",
    "                results.append(flattened_results)\n",
    "                writer.writerow(flattened_results)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar la pregunta: {str(e)}\")\n",
    "\n",
    "    print(f\"Resultados guardados en {output_file}\")\n",
    "    return results\n"
   ],
   "id": "7d28b1e490a4a174",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T00:51:06.703978Z",
     "start_time": "2024-07-21T00:51:06.695174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_results(results):\n",
    "    bleu_scores = [res['bleu_score'] for res in results]\n",
    "    rouge_1_scores = [res['rouge_scores_rouge-1'] for res in results]\n",
    "    rouge_2_scores = [res['rouge_scores_rouge-2'] for res in results]\n",
    "    rouge_l_scores = [res['rouge_scores_rouge-l'] for res in results]\n",
    "    source_relevance = [res['source_relevance'] for res in results]\n",
    "    response_times = [res['response_time'] for res in results]\n",
    "    questions = [res['question'] for res in results]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(questions, bleu_scores, label='BLEU Score')\n",
    "    plt.plot(questions, rouge_1_scores, label='ROUGE-1 Score')\n",
    "    plt.plot(questions, rouge_2_scores, label='ROUGE-2 Score')\n",
    "    plt.plot(questions, rouge_l_scores, label='ROUGE-L Score')\n",
    "    plt.plot(questions, source_relevance, label='Source Relevance')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(questions, response_times, label='Response Time', color='r')\n",
    "    plt.ylabel('Response Time (s)')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "3d2d20de893a095f",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-21T00:51:10.701050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejecución de pruebas con el RAGSystem\n",
    "rag_system = RAGSystem(pdf_directory=\"../data/GuideLines\", csv_file=\"../data/raw_data/BankCustomerChurnPrediction.csv\", base_dir=\"../data\")\n",
    "rag_system.run()  # Make sure to set up the system before running tests\n",
    "\n",
    "# Questions related to both CSV data and PDF documents\n",
    "questions = [\n",
    "    \"¿Cuál es el saldo promedio de los clientes?\", \n",
    "    \"¿Cuántos clientes tienen tarjeta de crédito?\",\n",
    "    \"¿Cuáles son las regulaciones sobre el cumplimiento bancario?\",  # PDF-related question\n",
    "    \"¿Qué recomendaciones se hacen en el documento PDF para la gestión de riesgos?\"  # PDF-related question\n",
    "]\n",
    "reference_answers = [\n",
    "    \"El saldo promedio de los clientes es 76,485.89 euros.\", \n",
    "    \"Un total de 7050 clientes tienen tarjeta de crédito.\",\n",
    "    \"Las regulaciones sobre el cumplimiento bancario incluyen medidas de KYC y AML.\",  # Expected answer based on PDF content\n",
    "    \"Las recomendaciones para la gestión de riesgos incluyen la implementación de controles internos efectivos.\"  # Expected answer based on PDF content\n",
    "]\n",
    "\n",
    "results = run_tests(rag_system, questions, reference_answers, \"resultados_test.csv\")\n",
    "\n",
    "# Plotting the results\n",
    "plot_results(results)"
   ],
   "id": "3664dfd78f3a79d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc31fdec6bba42f5bb63aa3e4bdfb184"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents processed: 1004\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d73b572a464f2a25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
